{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Verification and Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "background knowledge (original source from Coursera):\n",
    "\n",
    "**Face Verification** \"Is this the claimed person?\" For example, at some airports, you can pass through customs by letting a system scan your passport and then verifying that you (the person carrying the passport) are the correct person. A mobile phone that unlocks using your face is also using face verification. This is a 1:1 matching problem.\n",
    "\n",
    "**Face Recognition** \"Who is this person?\" For example, the video lecture showed a [face recognition video](https://www.youtube.com/watch?v=wr4rx0Spihs) of Baidu employees entering the office without needing to otherwise identify themselves. This is a 1:K matching problem.\n",
    "\n",
    "[FaceNet](https://arxiv.org/pdf/1503.03832.pdf)\n",
    "\n",
    "[DeepFace](https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a ConvNet to Compute Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('keras-facenet-h5/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights('keras-facenet-h5/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Face Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_encoding(image_path, model):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(160, 160))\n",
    "    img = np.around(np.array(img) / 255.0, decimals=12)\n",
    "    x_train = np.expand_dims(img, axis=0)\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding / np.linalg.norm(embedding, ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"danielle\"] = img_to_encoding(\"images/danielle.png\", model)\n",
    "database[\"younes\"] = img_to_encoding(\"images/younes.jpg\", model)\n",
    "database[\"tian\"] = img_to_encoding(\"images/tian.jpg\", model)\n",
    "database[\"andrew\"] = img_to_encoding(\"images/andrew.jpg\", model)\n",
    "database[\"kian\"] = img_to_encoding(\"images/kian.jpg\", model)\n",
    "database[\"dan\"] = img_to_encoding(\"images/dan.jpg\", model)\n",
    "database[\"sebastiano\"] = img_to_encoding(\"images/sebastiano.jpg\", model)\n",
    "database[\"bertrand\"] = img_to_encoding(\"images/bertrand.jpg\", model)\n",
    "database[\"kevin\"] = img_to_encoding(\"images/kevin.jpg\", model)\n",
    "database[\"felix\"] = img_to_encoding(\"images/felix.jpg\", model)\n",
    "database[\"benoit\"] = img_to_encoding(\"images/benoit.jpg\", model)\n",
    "database[\"arnaud\"] = img_to_encoding(\"images/arnaud.jpg\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(image_path, identity, database, model):\n",
    "    \"\"\"\n",
    "    Function that verifies if the person on the \"image_path\" image is \"identity\".\n",
    "\n",
    "    \"\"\"\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    dist = np.linalg.norm((encoding-database[identity]))\n",
    "\n",
    "    if dist<0.7:\n",
    "        print(\"It's \" + str(identity) + \", welcome in!\")\n",
    "        door_open = True\n",
    "    else:\n",
    "        print(\"It's not \" + str(identity) + \", please go away\")\n",
    "        door_open = False\n",
    "\n",
    "    return dist, door_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's younes, welcome in!\n"
     ]
    }
   ],
   "source": [
    "distance, door_open_flag = verify(\"images/camera_0.jpg\", \"younes\", database, model)\n",
    "assert np.isclose(distance, 0.5992949), \"Distance not as expected\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def who_is_it(image_path, database, model):\n",
    "    \"\"\"\n",
    "    Implements face recognition for the office by finding who is the person on the image_path image.\n",
    "    \n",
    "    \"\"\"\n",
    "    encoding =  img_to_encoding(image_path, model)\n",
    "    min_dist = 100\n",
    "    \n",
    "    for (name, db_enc) in database.items():\n",
    "        \n",
    "        dist = np.linalg.norm(encoding - db_enc)\n",
    "\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "\n",
    "    if min_dist > 0.8:\n",
    "        print(\"Not in the database.\")\n",
    "    else:\n",
    "        print (\"it's \" + str(identity))\n",
    "        \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's younes\n"
     ]
    }
   ],
   "source": [
    "test1 = who_is_it(\"images/camera_0.jpg\", database, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
